# Plan: Address Peer Review Feedback for SimCash Paper

**Date:** 2025-12-21
**Status:** Draft
**Priority:** High

## Overview

This plan addresses 13 issues raised in peer review of the SimCash paper generated by `docs/papers/simcash-paper/paper_generator`. The reviewer identified terminology problems, inconsistencies between claims and results, and documentation mismatches.

---

## Implementation Analysis: What The Code Actually Does

Before fixing the paper, I analyzed the actual implementation to understand what the code does vs. what the paper claims.

### Convergence Detection (from `api/payment_simulator/ai_cash_mgmt/optimization/convergence_detector.py`)

**Deterministic-Temporal Mode (Experiments 1 & 3):**
- Policies are **ALWAYS accepted** (line 2650 of `optimization.py`)
- Convergence based on **policy parameter stability** (`initial_liquidity_fraction`), NOT cost stability
- Requires ALL agents' `initial_liquidity_fraction` unchanged for `stability_window` iterations (default: 5)
- Multi-agent convergence: ALL optimized agents must have stable policies simultaneously (lines 2915-2927)

**Bootstrap Mode (Experiment 2):**
- Three criteria must ALL be satisfied (lines 488-490):
  1. **CV < 3%**: Coefficient of variation over last 5 iteration means
  2. **No trend**: Mann-Kendall test p > 0.05
  3. **Regret < 10%**: Current cost within 10% of best observed

### Acceptance Rule (from `api/payment_simulator/experiments/runner/optimization.py`)

**Bootstrap mode** (lines 2831-2834):
```python
# Accept if delta_sum > 0 (new policy is cheaper overall)
should_accept = evaluation.delta_sum > 0
```
- `delta_sum = sum(old_cost - new_cost)` across all bootstrap samples
- This is **sum of improvements**, NOT "improvement on all samples"

**Deterministic-temporal mode** (line 2650):
- Policies are **always accepted** - no cost-based rejection

### Agent Update Order (from `optimization.py` lines 810-890)

The iteration loop structure:
1. **Evaluate policies** (line 834): Run ONE simulation with BOTH agents' current policies
2. Both agents see their OWN costs from the SAME shared simulation
3. **Optimize each agent** (lines 886-888): Loop through agents sequentially, each proposes independently
4. Neither agent ever sees the other's proposal or policy (information isolation)

```python
for agent_id in self.optimized_agents:
    await self._optimize_agent(agent_id, ...)
```

**Key insight**: The sequential execution is purely an implementation detail. It does NOT create asymmetric first-mover dynamics because:
- Both agents observe costs from the **same** simulation evaluation (step 1)
- Both agents make proposals **independently** based on their own history
- Information isolation means neither ever sees the other's policy or costs

So "simultaneously" (information structure) and "sequentially" (code execution) are **not inconsistent** - just potentially confusing to readers.

---

## Summary of Issues

| # | Issue | Severity | Files Affected |
|---|-------|----------|----------------|
| 1 | "Nash equilibrium" too strong | üî¥ Critical | abstract.py, methods.py, discussion.py, conclusion.py |
| 2 | Convergence criterion doesn't match tables | üî¥ Critical | methods.py |
| 3 | Bootstrap acceptance rule mismatch | üü° Medium | methods.py |
| 4 | Sequential vs simultaneous ambiguity | üü¢ Minor (not actually inconsistent) | methods.py |
| 5 | "Successful recovery" claim inaccurate | üü° Medium | introduction.py |
| 6 | Free-rider interpretation issues | üü° Medium | discussion.py, results.py |
| 7 | Stochastic environment looks deterministic | üü° Medium | discussion.py |
| 8 | CV/Mann-Kendall clarification | üü¢ Minor | methods.py |
| 9 | Numbers/summary table inconsistencies | üü¢ Minor | discussion.py |
| 10 | Sample size vs language strength | üü° Medium | abstract.py, conclusion.py |
| 11 | RL vs LLM sample efficiency | üü¢ Minor | discussion.py |
| 12 | Authorship/LLM details | üü¢ Minor | (paper_builder.py - boilerplate) |
| 13 | Minor technical nits | üü¢ Minor | methods.py, appendices.py |

---

## Detailed Fix Plan

### Issue 1: "Nash equilibrium" terminology is too strong üî¥

**Problem:** The paper claims outcomes are "Nash equilibria" and "mutual best-response equilibria," but:
- Convergence is defined as "liquidity unchanged for 5 iterations," not "no unilateral deviation reduces cost"
- Policies are unconditionally accepted, even if they increase cost
- No formal Nash verification is performed

**Reviewer recommendation:** Soften to "equilibrium-like fixed points" or "fixed points of the update rule"

**Files to modify:**

#### `src/sections/abstract.py`
- Line 36: Change "Can Large Language Models discover Nash equilibria" ‚Üí "Can Large Language Models discover equilibrium-like behavior"
- Line 46: Change "reliably converge to stable equilibria" ‚Üí "reliably converge to stable fixed points"
- Line 48: Change "asymmetric free-rider equilibria" ‚Üí "asymmetric free-rider outcomes"
- Line 52-53: Add explicit caveat about not formally verifying Nash condition

#### `src/sections/methods.py`
- Line 123: Change "identify Nash equilibria" ‚Üí "identify stable policy profiles"
- Line 129: Change "indicating mutual best-response equilibrium" ‚Üí "indicating policy stability (treated as equilibrium-like behavior)"
- Add new paragraph in Section 2.5 explicitly stating: "We treat stable policy pairs as 'equilibria of the learning dynamics' but do not formally verify the Nash condition (i.e., we do not check that no unilateral deviation would reduce cost)."

#### `src/sections/discussion.py`
- Line 87: Change "converge to stable equilibria" ‚Üí "converge to stable policy profiles"
- Line 93: Change "observed equilibria" ‚Üí "observed outcomes"
- Line 109: Change "multiple asymmetric equilibria" ‚Üí "multiple asymmetric stable outcomes"
- Line 160: Change "symmetric games can support asymmetric equilibria" ‚Üí "symmetric games can converge to asymmetric stable outcomes under sequential optimization"

#### `src/sections/conclusion.py`
- Line 34: Change "discovering Nash equilibria" ‚Üí "discovering equilibrium-like behavior"
- Lines 45-46: Change "asymmetric free-rider equilibria" ‚Üí "asymmetric free-rider outcomes"
- Line 71: Change "select among multiple equilibria" ‚Üí "select among multiple stable outcomes"

#### `src/sections/results.py`
- Line 201: Change "asymmetric equilibrium" ‚Üí "asymmetric stable outcome"
- Line 216-218: Reframe discussion of "multiple equilibria" to "multiple stable outcomes"
- Line 282: Change "asymmetric equilibria" ‚Üí "asymmetric outcomes"

---

### Issue 2: Convergence criterion doesn't match tables üî¥

**Problem:** Section 2.5.1 says "Both agents' initial_liquidity_fraction unchanged for 5 consecutive iterations," but tables show:
- Exp 1 Pass 1: Stability only from iterations 5-8 (4 iterations)
- Exp 1 Pass 2: BANK_B liquidity wiggles until final iteration
- Exp 3: "Equilibrium" values repeat for only 2-4 iterations

**Root cause (from code analysis):**

The paper description is **partially wrong**. The actual implementation in `optimization.py` (lines 2900-2927):

1. **Policy stability check** uses `_is_stable_change()` which checks if relative change ‚â§ `stability_threshold` (default 5%)
2. This means "unchanged" really means "changed by ‚â§ 5%"
3. Multi-agent convergence requires ALL agents stable for `stability_window` (default 5) iterations

**The paper says "unchanged" but implementation allows ‚â§5% change.**

**Fix:**

#### `src/sections/methods.py`
- Line 129: Change from:
  > "Convergence criterion: Both agents' initial_liquidity_fraction unchanged for 5 consecutive iterations"

  To:
  > "Convergence criterion: Both agents' initial_liquidity_fraction stable (relative change ‚â§ 5%) for 5 consecutive iterations"

- Also clarify that in deterministic-temporal mode, **all policies are accepted** regardless of cost (the convergence is about when the LLM stops exploring, not cost improvement).

---

### Issue 3: Bootstrap acceptance rule text/math mismatch üü°

**Problem:** Section 2.5.2 says:
> "Accept if ‚àë·µ¢ Œ¥·µ¢ > 0 (improvement across all samples)"

But mathematically, ‚àë Œ¥·µ¢ > 0 means **positive average improvement**, not "improvement for all samples."

**Fix:**

#### `src/sections/methods.py`
- Line 140: Change "(improvement across all samples)" ‚Üí "(positive mean improvement across bootstrap samples)"
- Or more explicitly: "(i.e., average improvement across bootstrap samples)"

---

### Issue 4: Sequential vs simultaneous ambiguity üü¢ (Downgraded)

**Problem:** Two seemingly conflicting statements:
- Section 2.5.1: "counterparty policies evolve simultaneously"
- Section 2.7: "we optimize agents sequentially within each iteration"

**Root cause (from code analysis):**

These are NOT actually inconsistent:
- **"Simultaneously"** refers to the **information structure**: both agents observe the same shared simulation outcome, neither sees the other's policy or proposal
- **"Sequentially"** refers to **code execution**: implementation detail of the optimization loop

Due to **information isolation**, Agent B never sees Agent A's policy at all. Both agents:
1. See their own costs from the same simulation (evaluated at iteration start)
2. Make proposals independently based on their own history
3. Never observe the other's policy, costs, or proposals

The sequential execution does NOT create first-mover dynamics.

**Fix (minimal - just clarify):**

#### `src/sections/methods.py`
- Line 128: Leave "simultaneously" but add clarifying note:
  > "Rationale: Cost-based rejection would cause oscillation in multi-agent settings where counterparty policies evolve simultaneously. Note: 'simultaneously' refers to the information structure (neither agent observes the other's policy); the optimization code runs sequentially as an implementation detail."

OR simpler:
- Just leave as-is since it's not actually wrong, just potentially confusing to readers who don't understand the information isolation

---

### Issue 5: "Successful recovery" claim doesn't match results üü°

**Problem:** Contribution line 2 says:
> "Empirical Validation: Successful recovery of Castro et al.'s theoretical equilibria"

But:
- Experiment 2 only partially aligns (BANK_A ends ~5%, below 10-30% band)
- Experiment 3 explicitly does NOT recover symmetric predicted equilibrium

**Fix:**

#### `src/sections/introduction.py`
- Line 43-44: Change "Successful recovery of Castro et al.'s theoretical equilibria" ‚Üí "Empirical comparison with Castro et al.'s theoretical predictions, showing partial alignment and systematic deviations"

---

### Issue 6: Free-rider interpretation and multiple equilibria üü°

**Problem 1:** In Exp 1 Pass 3, the "free-rider" (BANK_B at 0%) has HIGHER cost ($70) than BANK_A ($31.78). Free-riders typically *benefit* by contributing less.

**Problem 2:** Inferring "the game has multiple equilibria" from different algorithm endpoints doesn't establish multiple Nash equilibria‚Äîjust multiple attractors.

**Fix:**

#### `src/sections/discussion.py`
- Lines 106-111: Clarify that Pass 3 represents a **failed coordination** rather than a true free-rider equilibrium
- Reframe: "BANK_B's zero-liquidity strategy in Pass 3 led to high costs for both agents, representing a coordination failure rather than successful free-riding"
- Lines 109-110: Change "game admits multiple asymmetric equilibria" ‚Üí "learning dynamics can converge to multiple asymmetric stable points with different efficiency properties"

#### `src/sections/results.py`
- Lines 212-218: Reframe Pass 3 as "coordination failure" not "alternative equilibrium"
- Add: "Note that BANK_B's zero-liquidity outcome in Pass 3, while stable, resulted in higher costs than Passes 1-2, representing a suboptimal fixed point rather than a true free-rider success."

---

### Issue 7: "Stochastic" environment looks nearly deterministic üü°

**Problem:** Experiment 2 iteration tables look almost perfectly smooth (near-linear cost decrease), despite being described as stochastic (Poisson arrivals, lognormal amounts).

**Root cause (from code + data analysis):**

The paper's explanation is **INCORRECT**. It says "context simulation holds transaction path fixed" - but that's not quite right.

**What actually happens:**
1. **Initial simulation** runs ONCE with `master_seed=42` (same across all passes - explains identical Iter 0 costs)
2. **Bootstrap samples** (50 of them) are generated from this ONE initial simulation's transaction history
3. These SAME 50 samples are reused for ALL iterations
4. Costs in the table are **bootstrap MEANS**, not individual simulation costs
5. Since all 50 samples are derived from the SAME underlying transaction history (just resampled), costs are highly correlated

**Evidence from data:**
- All 3 passes have **identical Iter 0 costs** ($498.00, $498.00) - same master_seed
- Costs change in smooth ~$50 steps - averaging across correlated samples

**The paper currently says:**
> "The iteration table above shows costs from the context simulation---the specific transaction realization"

**This is misleading.** The costs are actually bootstrap **means** across 50 samples, not a single realization.

**Fix:**

#### `src/sections/results.py` (lines 238-245)
- Change the explanation from "context simulation" to accurate description:
  > "The iteration table shows **mean costs** across 50 bootstrap samples. All samples are derived from the initial simulation's transaction history (generated once with a fixed seed), which explains why costs change smoothly as liquidity varies---the same underlying transactions are evaluated with different liquidity allocations."

#### `src/sections/discussion.py`
- Add clarification:
  > "The smoothness of iteration costs reflects that all bootstrap samples share the same underlying transaction history (resampled from the initial simulation). Cost variance appears in the final bootstrap statistics (Table X), not in iteration-by-iteration means."

---

### Issue 8: CV and Mann-Kendall clarification üü¢

**Problem 1:** Mann-Kendall test with only 5 iterations has very low power; p-values are coarse.

**Problem 2:** Table 5 shows very large CVs across bootstrap samples (128%), but convergence uses CV < 3%. Need to clarify these are different CVs.

**Fix:**

#### `src/sections/methods.py`
- Lines 141-146: Add clarification:
  > "Note: The Mann-Kendall test is a heuristic trend test over a short horizon; with only 5 iterations, statistical power is limited."
  > "The CV < 3% threshold is computed over the last 5 iteration means, not over individual bootstrap samples within an iteration (which can exhibit much higher variance, as shown in Table 5)."

---

### Issue 9: Numbers/summary table inconsistencies üü¢

**Problem:** Table 4.1.4 says Exp 2 "Observed: 6-20%" but actual reported values are 5-12%.

**Fix:**

#### `src/sections/discussion.py`
- Lines 173: Update summary table to show accurate observed range "5-12%" not "6-20%"

**Also:**
- Line 47-48 (conclusion): Nuance the "one agent minimizes while other compensates" claim:
  > "typically one agent settles on a very low liquidity fraction while the other maintains a higher fraction; even when both agents' costs are high (Exp 1 Pass 3), the outcomes remain asymmetric"

---

### Issue 10: Sample size vs strength of language üü°

**Problem:** Claims sound stronger than 9 preliminary runs support.

**Fixes:**

#### `src/sections/abstract.py`
- Line 46: Add "in our 9 preliminary runs" qualifier

#### `src/sections/conclusion.py`
- Line 45: Change "Asymmetric equilibria dominate" ‚Üí "Asymmetric outcomes dominate in our experiments"

#### `src/sections/discussion.py`
- Line 160: Change "This finding suggests that symmetric games can support asymmetric equilibria" ‚Üí "This finding suggests that, under our LLM update dynamics, symmetric games tend to converge to asymmetric outcomes"

---

### Issue 11: RL vs LLM sample efficiency comparison üü¢

**Problem:** Paper contrasts "50-100 RL episodes" with "7-29 LLM iterations," but bootstrap mode uses 50 samples √ó 2 policies = 100 simulations per iteration, so total simulations are comparable.

**Fix:**

#### `src/sections/discussion.py`
- Lines 206-208: Clarify comparison is about **decision steps** (iterations requiring LLM reasoning), not raw simulation count
- Add: "While each bootstrap iteration involves ~100 simulation samples for evaluation, the number of LLM decision points (policy proposals requiring reasoning) remains 7-29, compared to the continuous gradient updates in RL training."

---

### Issue 12: Authorship/LLM details üü¢

**Problem:** Listing Claude as "co-author" may distract collaborators; many venues disallow LLM authorship.

**Fix:**

#### Paper metadata (paper_builder.py or templates)
- Change authorship section to: "Developed with assistance from Claude 4.5 and GPT-5.2 as coding and writing tools; all experimental design and interpretation are the author's own."
- Keep detailed model configuration in Methods section

---

### Issue 13: Minor technical nits üü¢

**Problem 1:** Section 2.2 cost function list omits overdraft cost, but Section 2.4.1 includes it.

**Problem 2:** Appendix headings say "Symmetric Equilibrium ‚Äì Detailed Results" but observed outcomes are asymmetric.

**Problem 3:** Mixed decimal precision in tables.

**Fixes:**

#### `src/sections/methods.py`
- Line 39-45: Add overdraft cost to the cost function list:
  ```
  \item \textbf{Overdraft cost}: Fee for negative balance (basis points per day)
  ```

#### `src/sections/appendices.py`
- Rename "Symmetric Equilibrium ‚Äì Detailed Results" ‚Üí "Symmetric Scenario ‚Äì Detailed Results"

#### `src/latex/formatting.py`
- Harmonize decimal precision in format_percent() and format_money()

---

## Implementation Order

**Phase 1: Critical terminology fixes (Issues 1, 2)** ‚è±Ô∏è ~2 hours
1. Systematically replace "Nash equilibrium/equilibria" with "stable fixed point" / "equilibrium-like behavior"
2. Fix convergence criterion: "unchanged" ‚Üí "stable (relative change ‚â§ 5%)"
3. Regenerate paper and verify changes

**Phase 2: Accuracy fixes (Issues 3, 5, 6)** ‚è±Ô∏è ~1 hour
1. Fix bootstrap acceptance rule: "improvement across all samples" ‚Üí "positive sum of improvements"
2. Downgrade "successful recovery" ‚Üí "empirical comparison showing partial alignment"
3. Reframe free-rider interpretation (Pass 3 = coordination failure, not free-rider success)

**Phase 3: Clarity improvements (Issues 7, 8, 9, 10, 11)** ‚è±Ô∏è ~1 hour
1. Add explanation: context simulation uses fixed transaction path; stochasticity via bootstrap
2. Clarify CV: computed over iteration means, not individual samples
3. Fix Exp 2 observed range: "6-20%" ‚Üí "5-12%"
4. Add sample size qualifiers throughout
5. Clarify RL comparison: decision steps vs simulation count

**Phase 4: Polish (Issues 12, 13)** ‚è±Ô∏è ~30 mins
1. Update authorship to "assisted by" rather than "co-author"
2. Add overdraft cost to Section 2.2 cost function list
3. Rename appendix: "Symmetric Equilibrium" ‚Üí "Symmetric Scenario"
4. Harmonize decimal precision in formatting.py

---

## Testing Plan

After implementing fixes:

1. **Regenerate paper:**
   ```bash
   cd docs/papers/simcash-paper/paper_generator
   ./generate_paper.sh
   ```

2. **Verify terminology changes:**
   ```bash
   grep -n "Nash equilib" output/paper.tex  # Should be minimal/absent
   grep -n "stable.*point\|fixed point\|equilibrium-like" output/paper.tex  # Should appear
   ```

3. **Verify convergence criterion matches implementation:**
   - Check actual experiment runner code
   - Ensure methods.py matches

4. **Manual review:**
   - Read generated abstract, conclusion, discussion for consistency
   - Verify numerical claims match tables

5. **PDF compilation:**
   - Compile to PDF and visually inspect
   - Verify no LaTeX errors

---

## Open Questions for User

Before implementing, please confirm:

1. **Convergence criterion:** What is the actual implemented rule? Is it:
   - Exact match for 5 iterations?
   - Within some tolerance Œµ?
   - Different window size?

2. **Authorship preference:** Do you want to:
   - Remove Claude from author list entirely?
   - Keep as acknowledgment only?
   - Keep current phrasing?

3. **Priority:** Should I implement all fixes, or focus on critical/medium severity first?

---

## Files Modified Summary

| File | Changes |
|------|---------|
| `src/sections/abstract.py` | Lines 36, 46-48, 52-53: Soften equilibrium language |
| `src/sections/introduction.py` | Lines 43-44: Downgrade "successful recovery" |
| `src/sections/methods.py` | Lines 39-45, 123, 128-129, 140-147, 183: Fix convergence, acceptance, sequential/simultaneous |
| `src/sections/discussion.py` | Lines 87, 93, 109, 117-140, 160, 173, 206-208: Multiple fixes |
| `src/sections/results.py` | Lines 201, 212-218, 238-245, 282, 305-306: Terminology, explanation |
| `src/sections/conclusion.py` | Lines 34, 45-46, 71: Soften claims |
| `src/sections/appendices.py` | Heading rename |
| `src/latex/formatting.py` | Decimal precision harmonization |
| Paper metadata | Authorship clarification |

---

---

## Appendix: Specific Code Changes

### File: `src/sections/abstract.py`

```python
# Line 36: Soften opening question
# OLD: "Can Large Language Models discover Nash equilibria through strategic reasoning alone?"
# NEW: "Can Large Language Models discover equilibrium-like behavior through strategic reasoning alone?"

# Line 46: Soften convergence claim
# OLD: "reliably converge to stable equilibria"
# NEW: "reliably converge to stable policy profiles"

# Line 46: Add qualifier
# OLD: "({convergence_pct}\% success, mean {avg_iterations:.1f} iterations)"
# NEW: "({convergence_pct}\% success in our {total_passes} preliminary runs, mean {avg_iterations:.1f} iterations)"

# Lines 48-49: Soften equilibrium language
# OLD: "asymmetric free-rider equilibria"
# NEW: "asymmetric free-rider outcomes"

# Lines 52-53: Add caveat
# OLD: "equilibrium behavior without explicit game-theoretic modeling"
# NEW: "equilibrium-like behavior without explicit game-theoretic modeling (though we do not formally verify the Nash condition)"
```

### File: `src/sections/introduction.py`

```python
# Lines 43-44: Downgrade contribution claim
# OLD: "\item \textbf{Empirical Validation}: Successful recovery of Castro et al.'s theoretical equilibria"
# NEW: "\item \textbf{Empirical Comparison}: Comparison with Castro et al.'s theoretical predictions, showing partial alignment and systematic deviations"
```

### File: `src/sections/methods.py`

```python
# Lines 39-45: Add overdraft cost to list
# ADD after "Deadline penalty" item:
#     \item \textbf{Overdraft cost}: Fee for negative balance (basis points per day)

# Line 123: Soften Nash language
# OLD: "we use \textbf{temporal policy stability} to identify Nash equilibria"
# NEW: "we use \textbf{temporal policy stability} to identify stable policy profiles"

# Line 127: Clarify unconditional acceptance
# ADD after "Unconditional acceptance" item:
#     Note: In this mode, ALL LLM-proposed policies are accepted regardless of cost impact

# Line 128: Optionally clarify "simultaneously" (NOT actually wrong - see Issue 4 analysis)
# Leave as-is OR add clarifying note about information isolation

# Line 129: Fix convergence criterion
# OLD: "Both agents' initial_liquidity_fraction unchanged for 5 consecutive iterations, indicating mutual best-response equilibrium"
# NEW: "Both agents' initial_liquidity_fraction stable (relative change $\leq$ 5\%) for 5 consecutive iterations, indicating policy stability"

# Line 140: Fix acceptance rule description
# OLD: "(improvement across all samples)"
# NEW: "(positive sum of improvements across all samples)"

# Lines 141-146: Add CV clarification
# ADD note: "The CV threshold is computed over the last 5 \textit{iteration means}, not over individual bootstrap samples within an iteration."

# After line 183: (OPTIONAL - see Issue 4: sequential execution doesn't create asymmetric dynamics due to information isolation)
# If clarification desired, add note that "sequential" refers to code execution while "simultaneously" refers to information structure
```

### File: `src/sections/discussion.py`

```python
# Line 87: Soften equilibrium language
# OLD: "converge to stable equilibria"
# NEW: "converge to stable policy profiles"

# Line 93: Soften equilibrium language
# OLD: "observed equilibria"
# NEW: "observed outcomes"

# Lines 106-111: Reframe Pass 3 as coordination failure
# ADD after "role reversal" description:
#     Note that BANK\_B's zero-liquidity outcome, while stable, resulted in \textit{higher}
#     costs than the compensating agent---a coordination failure rather than successful free-riding.

# Lines 109-110: Soften multiple equilibria claim
# OLD: "the game admits \textbf{multiple asymmetric equilibria}"
# NEW: "the learning dynamics can converge to \textbf{multiple asymmetric stable outcomes}"

# Line 117-140: Add stochastic explanation (CORRECTED - see Issue 7 analysis)
# ADD after bootstrap stats discussion:
#     \textbf{Methodological note on smoothness:} The iteration costs shown are \textbf{bootstrap means}
#     across 50 samples. All samples are derived from the initial simulation's transaction history
#     (generated once with a fixed seed), so costs are highly correlated. As liquidity varies,
#     the mean cost changes smoothly. Cost variance appears in the final bootstrap statistics,
#     not in the iteration-by-iteration table.

# Line 160: Soften generalization
# OLD: "symmetric games can support asymmetric equilibria"
# NEW: "under our LLM update dynamics, symmetric games tend to converge to asymmetric stable outcomes"

# Line 173: Fix observed range
# OLD: "Observed: 6--20\%"
# NEW: "Observed: 5--12\%"

# Lines 206-208: Clarify sample efficiency comparison
# CHANGE "7--29 iterations" explanation to add:
#     While each bootstrap iteration involves $\sim$100 simulation samples for evaluation,
#     the number of LLM decision points (policy proposals requiring reasoning) remains 7--29.
```

### File: `src/sections/results.py`

```python
# Line 201: Soften equilibrium language
# OLD: "asymmetric equilibrium"
# NEW: "asymmetric stable outcome"

# Lines 212-218: Reframe Pass 3
# OLD: "the game admits multiple equilibria"
# NEW: "the learning dynamics can converge to multiple stable outcomes"

# ADD after line 218:
#     Note that the Pass 3 outcome, while stable, is \textit{not} Pareto-optimal---both agents
#     would prefer the efficient outcome from Passes 1--2. This represents a coordination failure
#     of the learning dynamics rather than a true free-rider success.

# Line 282: Soften equilibrium language
# OLD: "asymmetric equilibria"
# NEW: "asymmetric outcomes"

# Lines 305-306: Soften equilibrium language
# OLD: "asymmetric equilibria with free-rider behavior"
# NEW: "asymmetric stable outcomes with free-rider patterns"
```

### File: `src/sections/conclusion.py`

```python
# Line 34: Soften main claim
# OLD: "discovering Nash equilibria"
# NEW: "discovering equilibrium-like behavior"

# Lines 45-46: Soften and qualify
# OLD: "Asymmetric equilibria dominate"
# NEW: "Asymmetric outcomes dominate in our experiments"

# Lines 47-48: Nuance the compensation claim
# OLD: "One agent minimizes liquidity while the other compensates---a pattern that emerged in all nine passes"
# NEW: "Typically one agent settles on very low liquidity while the other maintains higher allocation; even in suboptimal outcomes (Exp 1 Pass 3), the results remain asymmetric"

# Line 71: Soften equilibrium selection claim
# OLD: "select among multiple equilibria"
# NEW: "select among multiple stable outcomes"
```

### File: `src/sections/appendices.py`

```python
# Find and replace heading
# OLD: "Symmetric Equilibrium ‚Äì Detailed Results"
# NEW: "Symmetric Scenario ‚Äì Detailed Results"
```

### File: Paper metadata (paper_builder.py or templates)

```python
# Find authorship section and change:
# OLD: "developed in collaboration with Claude 4.5 Opus (Anthropic), which served as a co-author"
# NEW: "developed with assistance from Claude 4.5 Opus (Anthropic) and GPT-5.2 (OpenAI) as coding and writing tools; all experimental design, analysis, and interpretation are the author's own"
```

---

## Terminology Replacement Summary

| Old Term | New Term | Rationale |
|----------|----------|-----------|
| Nash equilibrium/equilibria | stable policy profile / equilibrium-like behavior | Not formally verified as Nash |
| mutual best-response equilibrium | policy stability | Describes learning dynamics, not game theory |
| discover equilibria | discover equilibrium-like behavior | Softer claim |
| game admits multiple equilibria | learning dynamics can converge to multiple stable outcomes | About algorithm, not game |
| free-rider equilibrium | free-rider outcome / pattern | Outcome may not be true equilibrium |
| unchanged for 5 iterations | stable (‚â§5% change) for 5 iterations | Matches actual implementation |
| improvement across all samples | positive sum of improvements | Matches actual delta_sum criterion |
| ~~evolve simultaneously~~ | ~~n/a~~ | NOT a change needed - see Issue 4 (information isolation makes both terms valid) |

---

*Plan created: 2025-12-21*
